{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 23/23 [00:22<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NWPU-RESISC45, Spearman correlation: SignificanceResult(statistic=0.8166573537765787, pvalue=7.952020772809736e-12)\n",
      "Processed batch 1/2\n",
      "Processed batch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 59/59 [00:54<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Stanford_dogs, Spearman correlation: SignificanceResult(statistic=0.7259391551199936, pvalue=6.5836049796789e-21)\n",
      "Processed batch 1/4\n",
      "Processed batch 2/4\n",
      "Processed batch 3/4\n",
      "Processed batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 98/98 [04:19<00:00,  2.65s/it]\n",
      "C:\\Users\\Wuy19\\AppData\\Local\\Temp\\ipykernel_23780\\3247811251.py:128: RuntimeWarning: Mean of empty slice.\n",
      "  cur_class_accuracy = (cur_class_pred == c).mean()\n",
      "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CUB_200_2011, Spearman correlation: SignificanceResult(statistic=0.833884559388305, pvalue=9.652183689450992e-53)\n",
      "Processed batch 1/2\n",
      "Processed batch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 46/46 [00:45<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Flower102, Spearman correlation: SignificanceResult(statistic=0.6967831449517579, pvalue=4.444976788328451e-15)\n",
      "Processed batch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 493/493 [04:48<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: NWPU-RESISC45, Spearman correlation: SignificanceResult(statistic=0.8180500658761528, pvalue=6.850790104513321e-12)\n",
      "Processed batch 1/2\n",
      "Processed batch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 322/322 [03:43<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Stanford_dogs, Spearman correlation: SignificanceResult(statistic=0.8170845197583164, pvalue=5.3325877013584045e-30)\n",
      "Processed batch 1/4\n",
      "Processed batch 2/4\n",
      "Processed batch 3/4\n",
      "Processed batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 185/185 [02:31<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CUB_200_2011, Spearman correlation: SignificanceResult(statistic=0.8781028005954786, pvalue=2.6330984361777895e-65)\n",
      "Processed batch 1/2\n",
      "Processed batch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 128/128 [01:54<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Flower102, Spearman correlation: SignificanceResult(statistic=0.8870509216952215, pvalue=2.4270314261147215e-35)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from utils.dataset import get_dataset\n",
    "from utils.model_utils import load_model, get_text_embeddings, get_image_embeddings\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "# Define datasets and templates\n",
    "datasets_info = [\n",
    "    {\"name\": \"NWPU-RESISC45\", \"template\": \"a satellite photo containing {}.\"},\n",
    "    {\"name\": \"Stanford_dogs\", \"template\": \"a photo of {}, a type of dog.\"},\n",
    "    {\"name\": \"CUB_200_2011\", \"template\": \"a photo of {}, a type of bird.\"},\n",
    "    {\"name\": \"Flower102\", \"template\": \"a photo of {}, a type of flower.\"},\n",
    "]\n",
    "\n",
    "class PseudoImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, class_names, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_names = set(class_names)  # For faster lookup\n",
    "\n",
    "        for image_path in glob.glob(os.path.join(image_folder, '*.png')):\n",
    "            filename = os.path.basename(image_path)\n",
    "            class_name = filename.split('-')[0].replace('_', ' ')\n",
    "            if class_name in self.class_names:\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(class_name)\n",
    "        # convert labels to indices\n",
    "        self.labels = [class_names.index(label) for label in self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_image_loader(dataset, class_indices, batch_size, shuffle=False):\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        selected_indices = [i for i, label in enumerate(dataset.targets) if label in class_indices]\n",
    "    else:\n",
    "        selected_indices = [i for i, (_, label) in enumerate(dataset.imgs) if label in class_indices]\n",
    "    selected_dataset = Subset(dataset, selected_indices)\n",
    "\n",
    "    # Set no transform for simplicity (depends on dataset loading code)\n",
    "    selected_dataset.dataset.transform = None\n",
    "\n",
    "    loader = DataLoader(\n",
    "        selected_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])  # Custom collate\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def run_experiment(dataset_name, template):\n",
    "    # 1. Load dataset (test split)\n",
    "    dataset = get_dataset(dataset_name, data_root='data', split='test')\n",
    "    class_names = dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "    # Create dataloader\n",
    "    if USE_PSEUDO_DATA:\n",
    "        PSEUDO_IMAGES_FOLDER = f'pseudo_images/{dataset_name}'\n",
    "        pseudo_dataset = PseudoImageDataset(\n",
    "            image_folder=PSEUDO_IMAGES_FOLDER,\n",
    "            class_names=dataset.classes,\n",
    "            transform=None  # Add transformations if required\n",
    "        )\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            pseudo_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])  # Custom collate function\n",
    "        )\n",
    "    else:\n",
    "        selected_class_indices = list(range(num_classes))\n",
    "        dataloader = get_image_loader(dataset, selected_class_indices, 64, shuffle=False)\n",
    "\n",
    "    # 2. Load model\n",
    "    model_info = load_model(model_name, device=device)\n",
    "\n",
    "    # 3. Create captions and compute text embeddings\n",
    "    captions = [template.format(c) for c in class_names]\n",
    "    text_embeddings = get_text_embeddings(captions, model_info, device, batch_size=64)\n",
    "\n",
    "    # 4. Compute image embeddings\n",
    "    image_embeddings, all_targets = get_image_embeddings(dataloader, model_info, device)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "    text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # 5. Compute similarities and predictions\n",
    "    temperature = 0.01\n",
    "    similarities = np.matmul(image_embeddings, text_embeddings.T) / temperature\n",
    "    probs = np.exp(similarities) / np.sum(np.exp(similarities), axis=1, keepdims=True)\n",
    "\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "\n",
    "    # Compute class-wise actual and predicted accuracies\n",
    "    actual_accuracies = []\n",
    "    predicted_accuracies = []\n",
    "    for c in range(num_classes):\n",
    "        cur_class_indices = (all_targets == c)\n",
    "        cur_class_pred = preds[cur_class_indices]\n",
    "        cur_class_accuracy = (cur_class_pred == c).mean()\n",
    "        if np.isnan(cur_class_accuracy):\n",
    "            continue\n",
    "        \n",
    "        predicted_cur_class_indices = (preds == c)\n",
    "        predicted_confidences = confidences[predicted_cur_class_indices]\n",
    "        predicted_acc = predicted_confidences.mean() if predicted_confidences.size > 0 else np.nan\n",
    "\n",
    "        actual_accuracies.append(cur_class_accuracy)\n",
    "        if not np.isnan(predicted_acc):\n",
    "            predicted_accuracies.append(predicted_acc)\n",
    "        else:\n",
    "            predicted_accuracies.append(0.0)\n",
    "            \n",
    "    # Compute Spearman correlation\n",
    "    spearman_corr = spearmanr(np.array(actual_accuracies), np.array(predicted_accuracies))\n",
    "    print(f\"Dataset: {dataset_name}, Spearman correlation: {spearman_corr}\")\n",
    "\n",
    "    # Plot and save\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    if USE_PSEUDO_DATA: # orange\n",
    "        color = 'tab:orange'\n",
    "    else: # blue\n",
    "        color = 'tab:blue'\n",
    "    ax.scatter(predicted_accuracies, actual_accuracies, color=color)\n",
    "    ax.set_xlabel(\"Predicted Accuracy (Confidence)\")\n",
    "    ax.set_ylabel(\"Actual Accuracy\")\n",
    "    if USE_PSEUDO_DATA:\n",
    "        title_name = f\"Calibration Approach: {dataset_name} with Pseudo Images\\n Spearman Correlation: {spearman_corr[0]:.2f}\"\n",
    "    else:\n",
    "        title_name = f\"Calibration Approach: {dataset_name} with Real Images\\n Spearman Correlation: {spearman_corr[0]:.2f}\"\n",
    "    ax.set_title(title_name)\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    if USE_PSEUDO_DATA:\n",
    "        plot_filename = f\"figures/{dataset_name}_pseudo_pred_vs_actual.png\"\n",
    "    else:\n",
    "        plot_filename = f\"figures/{dataset_name}_pred_vs_actual.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Run experiments for each dataset\n",
    "\n",
    "USE_PSEUDO_DATA = True\n",
    "for dinfo in datasets_info:\n",
    "    run_experiment(dinfo[\"name\"], dinfo[\"template\"])\n",
    "USE_PSEUDO_DATA = False\n",
    "for dinfo in datasets_info:\n",
    "    run_experiment(dinfo[\"name\"], dinfo[\"template\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102_global_traits.json\n",
      "Using OpenAI model: gpt-4o-mini-2024-07-18\n",
      "Configured to generate 40 captions.\n",
      "Meta Prompt: You are an AI assistant that generates creative and diverse image captions suitable for use with image generation models like DALL-E. Given a subject, provide 40 distinct, diverse and descriptive captions, considering the following global taxonomical traits when generating captions: ['Petal arrangement', 'Leaf shape', 'Flower color', 'Growth habit (herbaceous vs. woody)', 'Stem structure', 'Pollination mechanism', 'Geographic distribution', 'Habitat preference (aquatic, terrestrial)', 'Fruit type (dry, fleshy)', 'Root system (fibrous vs. taproot)', 'Seasonality (annual, perennial)', 'Height and size variation', 'Reproductive structures (e.g., presence of sepals, stamens)', 'Symmetry of flowers (radial vs. bilateral)', 'Response to climate conditions', 'Association with specific insects or animals'].\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\alpine_sea_holly.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\anthurium.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\artichoke.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\azalea.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\ball_moss.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\balloon_flower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\barbeton_daisy.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bearded_iris.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bee_balm.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bird_of_paradise.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bishop_of_llandaff.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\black-eyed_susan.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\blackberry_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\blanket_flower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bolero_deep_blue.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bougainvillea.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\bromelia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\buttercup.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\californian_poppy.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\camellia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\canna_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\canterbury_bells.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\cape_flower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\carnation.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\cautleya_spicata.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\clematis.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\colt's_foot.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\columbine.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\common_dandelion.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\corn_poppy.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\cyclamen.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\daffodil.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\desert-rose.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\english_marigold.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\fire_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\foxglove.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\frangipani.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\fritillary.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\garden_phlox.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\gaura.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\gazania.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\geranium.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\giant_white_arum_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\globe_thistle.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\globe-flower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\grape_hyacinth.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\great_masterwort.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\hard-leaved_pocket_orchid.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\hibiscus.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\hippeastrum.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\japanese_anemone.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\king_protea.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\lenten_rose.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\lotus.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\love_in_the_mist.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\magnolia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\mallow.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\marigold.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\mexican_aster.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\mexican_petunia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\monkshood.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\moon_orchid.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\morning_glory.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\orange_dahlia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\osteospermum.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\oxeye_daisy.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\passion_flower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\pelargonium.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\peruvian_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\petunia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\pincushion_flower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\pink_primrose.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\pink-yellow_dahlia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\poinsettia.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\primula.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\prince_of_wales_feathers.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\purple_coneflower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\red_ginger.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\rose.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\ruby-lipped_cattleya.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\siam_tulip.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\silverbush.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\snapdragon.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\spear_thistle.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\spring_crocus.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\stemless_gentian.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\sunflower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\sweet_pea.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\sweet_william.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\sword_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\thorn_apple.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\tiger_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\toad_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\tree_mallow.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\tree_poppy.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\trumpet_creeper.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\wallflower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\water_lily.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\watercress.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\wild_pansy.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\windflower.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\Flower102\\40\\yellow_iris.json\n",
      "Processed batch 1/2\n",
      "Processed batch 2/2\n",
      "Processed batch 1/60\n",
      "Processed batch 2/60\n",
      "Processed batch 3/60\n",
      "Processed batch 4/60\n",
      "Processed batch 5/60\n",
      "Processed batch 6/60\n",
      "Processed batch 7/60\n",
      "Processed batch 8/60\n",
      "Processed batch 9/60\n",
      "Processed batch 10/60\n",
      "Processed batch 11/60\n",
      "Processed batch 12/60\n",
      "Processed batch 13/60\n",
      "Processed batch 14/60\n",
      "Processed batch 15/60\n",
      "Processed batch 16/60\n",
      "Processed batch 17/60\n",
      "Processed batch 18/60\n",
      "Processed batch 19/60\n",
      "Processed batch 20/60\n",
      "Processed batch 21/60\n",
      "Processed batch 22/60\n",
      "Processed batch 23/60\n",
      "Processed batch 24/60\n",
      "Processed batch 25/60\n",
      "Processed batch 26/60\n",
      "Processed batch 27/60\n",
      "Processed batch 28/60\n",
      "Processed batch 29/60\n",
      "Processed batch 30/60\n",
      "Processed batch 31/60\n",
      "Processed batch 32/60\n",
      "Processed batch 33/60\n",
      "Processed batch 34/60\n",
      "Processed batch 35/60\n",
      "Processed batch 36/60\n",
      "Processed batch 37/60\n",
      "Processed batch 38/60\n",
      "Processed batch 39/60\n",
      "Processed batch 40/60\n",
      "Processed batch 41/60\n",
      "Processed batch 42/60\n",
      "Processed batch 43/60\n",
      "Processed batch 44/60\n",
      "Processed batch 45/60\n",
      "Processed batch 46/60\n",
      "Processed batch 47/60\n",
      "Processed batch 48/60\n",
      "Processed batch 49/60\n",
      "Processed batch 50/60\n",
      "Processed batch 51/60\n",
      "Processed batch 52/60\n",
      "Processed batch 53/60\n",
      "Processed batch 54/60\n",
      "Processed batch 55/60\n",
      "Processed batch 56/60\n",
      "Processed batch 57/60\n",
      "Processed batch 58/60\n",
      "Processed batch 59/60\n",
      "Processed batch 60/60\n",
      "Dataset: Flower102, Spearman correlation: SignificanceResult(statistic=nan, pvalue=nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wuy19\\AppData\\Local\\Temp\\ipykernel_67232\\2991955679.py:63: RuntimeWarning: Mean of empty slice.\n",
      "  cur_class_accuracy = (cur_class_pred == c).mean()\n",
      "c:\\ProgramData\\miniconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Run experiments for each dataset\n",
    "# for dinfo in datasets_info:\n",
    "#     run_experiment(dinfo[\"name\"], dinfo[\"template\"])\n",
    "dataset_name = dinfo[\"name\"]\n",
    "template = dinfo[\"template\"]\n",
    "# def run_experiment(dataset_name, template):\n",
    "    # 1. Load dataset (test split)\n",
    "dataset = get_dataset(dataset_name, data_root='data', split='test')\n",
    "class_names = dataset.classes\n",
    "num_classes = len(class_names)\n",
    "from utils.utils import CaptionGenerator\n",
    "\n",
    "# Initialize CaptionGenerator and generate alternative captions\n",
    "capGenerator = CaptionGenerator(dataset_name=dataset_name, class_names=class_names, num_captions=40)\n",
    "\n",
    "alter_caption_list = []\n",
    "labels = []\n",
    "all_targets = []\n",
    "for class_name in class_names:\n",
    "    alter_captions = capGenerator.get_alternative_captions(class_name)\n",
    "    alter_caption_list.extend(alter_captions)\n",
    "    labels.extend([class_name] * len(alter_captions))\n",
    "    all_targets.extend([class_names.index(class_name)] * len(alter_captions))\n",
    "\n",
    "selected_class_indices = list(range(num_classes))\n",
    "dataloader = get_image_loader(dataset, selected_class_indices, 64, shuffle=False)\n",
    "\n",
    "# 2. Load model\n",
    "model_info = load_model(model_name, device=device)\n",
    "\n",
    "# 3. Create captions and compute text embeddings\n",
    "captions = [template.format(c) for c in class_names]\n",
    "text_embeddings = get_text_embeddings(captions, model_info, device, batch_size=64)\n",
    "\n",
    "# 4. Compute alternative caption embeddings\n",
    "descriptive_text_embeddings = get_text_embeddings(alter_caption_list, model_info, device, batch_size=64)\n",
    "\n",
    "# image_embeddings, all_targets = get_image_embeddings(dataloader, model_info, device)\n",
    "# all_targets = np.array(all_targets)\n",
    "\n",
    "# Normalize embeddings\n",
    "# image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "descriptive_text_embeddings = descriptive_text_embeddings / np.linalg.norm(descriptive_text_embeddings, axis=1, keepdims=True)\n",
    "text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# descriptive text shape: (num_classes * num_captions, embedding_dim)\n",
    "# text_embeddings shape: (num_classes, embedding_dim)\n",
    "\n",
    "# 5. Compute similarities and predictions\n",
    "temperature = 0.07\n",
    "similarities = np.matmul(descriptive_text_embeddings, text_embeddings.T) / temperature\n",
    "probs = np.exp(similarities) / np.sum(np.exp(similarities), axis=1, keepdims=True)\n",
    "\n",
    "preds = np.argmax(probs, axis=1)\n",
    "confidences = np.max(probs, axis=1)\n",
    "\n",
    "# Compute class-wise actual and predicted accuracies\n",
    "actual_accuracies = []\n",
    "predicted_accuracies = []\n",
    "for c in range(num_classes):\n",
    "    cur_class_indices = (all_targets == c)\n",
    "    cur_class_pred = preds[cur_class_indices]\n",
    "    cur_class_accuracy = (cur_class_pred == c).mean()\n",
    "    if np.isnan(cur_class_accuracy):\n",
    "        continue\n",
    "    \n",
    "    predicted_cur_class_indices = (preds == c)\n",
    "    predicted_confidences = confidences[predicted_cur_class_indices]\n",
    "    predicted_acc = predicted_confidences.mean() if predicted_confidences.size > 0 else np.nan\n",
    "\n",
    "    actual_accuracies.append(cur_class_accuracy)\n",
    "    if not np.isnan(predicted_acc):\n",
    "        predicted_accuracies.append(predicted_acc)\n",
    "    else:\n",
    "        predicted_accuracies.append(0.0)\n",
    "        \n",
    "# Compute Spearman correlation\n",
    "spearman_corr = spearmanr(np.array(actual_accuracies), np.array(predicted_accuracies))\n",
    "print(f\"Dataset: {dataset_name}, Spearman correlation: {spearman_corr}\")\n",
    "\n",
    "# Plot and save\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.scatter(predicted_accuracies, actual_accuracies)\n",
    "ax.set_xlabel(\"Predicted Accuracy (Confidence)\")\n",
    "ax.set_ylabel(\"Actual Accuracy\")\n",
    "ax.set_title(f\"{dataset_name}: Predicted vs. Actual Accuracy per Class\\n Spearman Correlation: {spearman_corr[0]:.2f}\")\n",
    "ax.grid(True)\n",
    "\n",
    "plot_filename = f\"{dataset_name}_pred_vs_actual.png\"\n",
    "plt.savefig(plot_filename)\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99998987e-01, 7.78778277e-26, 7.06572385e-17, ...,\n",
       "        8.25450803e-21, 4.14319259e-21, 9.51531882e-28],\n",
       "       [1.00000000e+00, 8.36850962e-22, 2.20842442e-13, ...,\n",
       "        3.51010122e-17, 1.05598439e-16, 1.12418414e-23],\n",
       "       [9.99999642e-01, 1.40198842e-20, 7.73849775e-14, ...,\n",
       "        2.03927628e-18, 1.29697553e-17, 3.74584931e-25],\n",
       "       ...,\n",
       "       [9.05913343e-21, 2.80029886e-17, 1.04934279e-14, ...,\n",
       "        1.21163184e-11, 1.18866200e-14, 9.99999166e-01],\n",
       "       [6.35460261e-21, 1.46658659e-17, 7.36505312e-15, ...,\n",
       "        3.08224557e-11, 6.75076789e-16, 9.99908686e-01],\n",
       "       [4.93357346e-22, 1.46807395e-18, 1.36964031e-15, ...,\n",
       "        1.73707305e-12, 1.12639857e-16, 9.99999821e-01]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/4\n",
      "Processed batch 2/4\n",
      "Processed batch 3/4\n",
      "Processed batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 98/98 [05:33<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/4\n",
      "Processed batch 2/4\n",
      "Processed batch 3/4\n",
      "Processed batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 185/185 [02:31<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from utils.dataset import get_dataset\n",
    "from utils.model_utils import load_model, get_text_embeddings, get_image_embeddings\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "datasets_info = [\n",
    "    # {\"name\": \"NWPU-RESISC45\", \"template\": \"a satellite photo containing {}.\"},\n",
    "    # {\"name\": \"Stanford_dogs\", \"template\": \"a photo of {}, a type of dog.\"},\n",
    "    {\"name\": \"CUB_200_2011\", \"template\": \"a photo of {}, a type of bird.\"},\n",
    "    # {\"name\": \"Flower102\", \"template\": \"a photo of {}, a type of flower.\"},\n",
    "]\n",
    "\n",
    "class PseudoImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, class_names, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_names = class_names\n",
    "\n",
    "        # Store class_names in a set for faster lookup\n",
    "        class_name_set = set(class_names)\n",
    "\n",
    "        for image_path in glob.glob(os.path.join(image_folder, '*.png')):\n",
    "            filename = os.path.basename(image_path)\n",
    "            class_name = filename.split('-')[0].replace('_', ' ')\n",
    "            if class_name in class_name_set:\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(class_name)\n",
    "\n",
    "        # Convert labels to indices\n",
    "        self.labels = [class_names.index(label) for label in self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_image_loader(dataset, class_indices, batch_size, shuffle=False):\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        selected_indices = [i for i, label in enumerate(dataset.targets) if label in class_indices]\n",
    "    else:\n",
    "        selected_indices = [i for i, (_, label) in enumerate(dataset.imgs) if label in class_indices]\n",
    "    selected_dataset = Subset(dataset, selected_indices)\n",
    "\n",
    "    # Ensure no transform or compatible transform is applied\n",
    "    selected_dataset.dataset.transform = None\n",
    "\n",
    "    loader = DataLoader(\n",
    "        selected_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def run_experiment(dataset_name, template, use_pseudo_data):\n",
    "    # 1. Load dataset (test split)\n",
    "    dataset = get_dataset(dataset_name, data_root='data', split='test')\n",
    "    class_names = dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    if use_pseudo_data:\n",
    "        PSEUDO_IMAGES_FOLDER = f'pseudo_images/{dataset_name}'\n",
    "        pseudo_dataset = PseudoImageDataset(\n",
    "            image_folder=PSEUDO_IMAGES_FOLDER,\n",
    "            class_names=class_names,\n",
    "            transform=None\n",
    "        )\n",
    "        dataloader = DataLoader(\n",
    "            pseudo_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])\n",
    "        )\n",
    "    else:\n",
    "        selected_class_indices = list(range(num_classes))\n",
    "        dataloader = get_image_loader(dataset, selected_class_indices, 64, shuffle=False)\n",
    "\n",
    "    # 2. Load model\n",
    "    model_info = load_model(model_name, device=device)\n",
    "\n",
    "    # 3. Create captions and compute text embeddings\n",
    "    captions = [template.format(c) for c in class_names]\n",
    "    text_embeddings = get_text_embeddings(captions, model_info, device, batch_size=64)\n",
    "\n",
    "    # 4. Compute image embeddings\n",
    "    image_embeddings, all_targets = get_image_embeddings(dataloader, model_info, device)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "    text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # 5. Compute similarities and predictions\n",
    "    temperature = 0.01\n",
    "    similarities = np.matmul(image_embeddings, text_embeddings.T) / temperature\n",
    "    probs = np.exp(similarities) / np.sum(np.exp(similarities), axis=1, keepdims=True)\n",
    "\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "    confidences = np.max(probs, axis=1)\n",
    "\n",
    "    # Compute class-wise actual and predicted accuracies\n",
    "    actual_accuracies = []\n",
    "    predicted_accuracies = []\n",
    "    for c in range(num_classes):\n",
    "        cur_class_indices = (all_targets == c)\n",
    "        if cur_class_indices.sum() == 0:\n",
    "            continue\n",
    "        cur_class_pred = preds[cur_class_indices]\n",
    "        cur_class_accuracy = (cur_class_pred == c).mean()\n",
    "        if np.isnan(cur_class_accuracy):\n",
    "            continue\n",
    "        \n",
    "        predicted_cur_class_indices = (preds == c)\n",
    "        predicted_confidences = confidences[predicted_cur_class_indices]\n",
    "        predicted_acc = predicted_confidences.mean() if predicted_confidences.size > 0 else np.nan\n",
    "\n",
    "        actual_accuracies.append(cur_class_accuracy)\n",
    "        predicted_accuracies.append(predicted_acc if not np.isnan(predicted_acc) else 0.0)\n",
    "            \n",
    "    # Compute Spearman correlation\n",
    "    spearman_corr = spearmanr(np.array(actual_accuracies), np.array(predicted_accuracies))\n",
    "\n",
    "    # Return data for plotting outside\n",
    "    return np.array(actual_accuracies), np.array(predicted_accuracies), spearman_corr\n",
    "\n",
    "\n",
    "# Now we call run_experiment for pseudo and real data and plot them together\n",
    "for dinfo in datasets_info:\n",
    "    actual_pseudo, predicted_pseudo, spearman_pseudo = run_experiment(dinfo[\"name\"], dinfo[\"template\"], use_pseudo_data=True)\n",
    "    actual_real, predicted_real, spearman_real = run_experiment(dinfo[\"name\"], dinfo[\"template\"], use_pseudo_data=False)\n",
    "\n",
    "    # Create a single plot for both pseudo and real\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    ax.scatter(predicted_pseudo, actual_pseudo, color='tab:orange', label='Pseudo Images', alpha = 0.5)\n",
    "    ax.scatter(predicted_real, actual_real, color='tab:blue', label='Real Images', alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted Accuracy (Confidence)\")\n",
    "    ax.set_ylabel(\"Actual Accuracy\")\n",
    "    pseudo_corr_str = f\"{spearman_pseudo.correlation:.2f}\" if spearman_pseudo.correlation is not None else \"N/A\"\n",
    "    real_corr_str = f\"{spearman_real.correlation:.2f}\" if spearman_real.correlation is not None else \"N/A\"\n",
    "    ax.set_title(f\"Calibration Approach: {dinfo['name']}\\nSpearman (Pseudo): {pseudo_corr_str}, Spearman (Real): {real_corr_str}\")\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "\n",
    "    # Save the figure\n",
    "    plot_filename = f\"figures/{dinfo['name']}_combined_pred_vs_actual.png\"\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/4\n",
      "Processed batch 2/4\n",
      "Processed batch 3/4\n",
      "Processed batch 4/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 185/185 [01:14<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: CUB_200_2011, Spearman correlation: SignificanceResult(statistic=0.8906007894462, pvalue=1.1184070199550016e-69)\n",
      "Dataset: CUB_200_2011, Spearman correlation: SignificanceResult(statistic=0.8781028005954786, pvalue=2.6330984361777895e-65)\n",
      "Dataset: CUB_200_2011, Spearman correlation: SignificanceResult(statistic=0.6701227937060699, pvalue=1.964492082710588e-27)\n",
      "Dataset: CUB_200_2011, Spearman correlation: SignificanceResult(statistic=0.5945655086098027, pvalue=1.662329032885547e-20)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from utils.dataset import get_dataset\n",
    "from utils.model_utils import load_model, get_text_embeddings, get_image_embeddings\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_name = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "# Define datasets and templates\n",
    "datasets_info = [\n",
    "    # {\"name\": \"NWPU-RESISC45\", \"template\": \"a satellite photo containing {}.\"},\n",
    "    # {\"name\": \"Stanford_dogs\", \"template\": \"a photo of {}, a type of dog.\"},\n",
    "    {\"name\": \"CUB_200_2011\", \"template\": \"a photo of {}, a type of bird.\"},\n",
    "    # {\"name\": \"Flower102\", \"template\": \"a photo of {}, a type of flower.\"},\n",
    "]\n",
    "\n",
    "class PseudoImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, class_names, transform=None):\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.class_names = set(class_names)  # For faster lookup\n",
    "\n",
    "        for image_path in glob.glob(os.path.join(image_folder, '*.png')):\n",
    "            filename = os.path.basename(image_path)\n",
    "            class_name = filename.split('-')[0].replace('_', ' ')\n",
    "            if class_name in self.class_names:\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(class_name)\n",
    "        # convert labels to indices\n",
    "        self.labels = [class_names.index(label) for label in self.labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def get_image_loader(dataset, class_indices, batch_size, shuffle=False):\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        selected_indices = [i for i, label in enumerate(dataset.targets) if label in class_indices]\n",
    "    else:\n",
    "        selected_indices = [i for i, (_, label) in enumerate(dataset.imgs) if label in class_indices]\n",
    "    selected_dataset = Subset(dataset, selected_indices)\n",
    "\n",
    "    # Set no transform for simplicity (depends on dataset loading code)\n",
    "    selected_dataset.dataset.transform = None\n",
    "\n",
    "    loader = DataLoader(\n",
    "        selected_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])  # Custom collate\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def run_experiment(dataset_name, template):\n",
    "    # 1. Load dataset (test split)\n",
    "    dataset = get_dataset(dataset_name, data_root='data', split='test')\n",
    "    class_names = dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "    # Create dataloader\n",
    "    if USE_PSEUDO_DATA:\n",
    "        PSEUDO_IMAGES_FOLDER = f'pseudo_images/{dataset_name}'\n",
    "        pseudo_dataset = PseudoImageDataset(\n",
    "            image_folder=PSEUDO_IMAGES_FOLDER,\n",
    "            class_names=dataset.classes,\n",
    "            transform=None  # Add transformations if required\n",
    "        )\n",
    "\n",
    "        dataloader = DataLoader(\n",
    "            pseudo_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])  # Custom collate function\n",
    "        )\n",
    "    else:\n",
    "        selected_class_indices = list(range(num_classes))\n",
    "        dataloader = get_image_loader(dataset, selected_class_indices, 64, shuffle=False)\n",
    "\n",
    "    # 2. Load model\n",
    "    model_info = load_model(model_name, device=device)\n",
    "\n",
    "    # 3. Create captions and compute text embeddings\n",
    "    captions = [template.format(c) for c in class_names]\n",
    "    text_embeddings = get_text_embeddings(captions, model_info, device, batch_size=64)\n",
    "\n",
    "    # 4. Compute image embeddings\n",
    "    image_embeddings, all_targets = get_image_embeddings(dataloader, model_info, device)\n",
    "    all_targets = np.array(all_targets)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, axis=1, keepdims=True)\n",
    "    text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "    # 5. Compute similarities and predictions\n",
    "    # temperature = 0.01\n",
    "    for temperature in [0.005, 0.01, 0.05, 0.1]:\n",
    "        similarities = np.matmul(image_embeddings, text_embeddings.T) / temperature\n",
    "        probs = np.exp(similarities) / np.sum(np.exp(similarities), axis=1, keepdims=True)\n",
    "\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        confidences = np.max(probs, axis=1)\n",
    "\n",
    "        # Compute class-wise actual and predicted accuracies\n",
    "        actual_accuracies = []\n",
    "        predicted_accuracies = []\n",
    "        for c in range(num_classes):\n",
    "            cur_class_indices = (all_targets == c)\n",
    "            cur_class_pred = preds[cur_class_indices]\n",
    "            cur_class_accuracy = (cur_class_pred == c).mean()\n",
    "            if np.isnan(cur_class_accuracy):\n",
    "                continue\n",
    "            \n",
    "            predicted_cur_class_indices = (preds == c)\n",
    "            predicted_confidences = confidences[predicted_cur_class_indices]\n",
    "            predicted_acc = predicted_confidences.mean() if predicted_confidences.size > 0 else np.nan\n",
    "\n",
    "            actual_accuracies.append(cur_class_accuracy)\n",
    "            if not np.isnan(predicted_acc):\n",
    "                predicted_accuracies.append(predicted_acc)\n",
    "            else:\n",
    "                predicted_accuracies.append(0.0)\n",
    "                \n",
    "        # Compute Spearman correlation\n",
    "        spearman_corr = spearmanr(np.array(actual_accuracies), np.array(predicted_accuracies))\n",
    "        print(f\"Dataset: {dataset_name}, Spearman correlation: {spearman_corr}\")\n",
    "\n",
    "        # Plot and save\n",
    "        fig, ax = plt.subplots(figsize=(8,8))\n",
    "        if USE_PSEUDO_DATA: # orange\n",
    "            color = 'tab:orange'\n",
    "        else: # blue\n",
    "            color = 'tab:blue'\n",
    "        ax.scatter(predicted_accuracies, actual_accuracies, color=color)\n",
    "        ax.set_xlabel(\"Predicted Accuracy (Confidence)\")\n",
    "        ax.set_ylabel(\"Actual Accuracy\")\n",
    "        if USE_PSEUDO_DATA:\n",
    "            title_name = f\"Calibration Approach: {dataset_name} with Pseudo Images (Temperature = {1/temperature})\\n Spearman Correlation: {spearman_corr[0]:.2f}\"\n",
    "        else:\n",
    "            title_name = f\"Calibration Approach: {dataset_name} with Real Images (Temperature = {1/temperature})\\n Spearman Correlation: {spearman_corr[0]:.2f}\"\n",
    "        ax.set_title(title_name)\n",
    "        ax.grid(True)\n",
    "        # ax.set_xlim([0, 1])\n",
    "        # ax.set_ylim([0, 1])\n",
    "        if USE_PSEUDO_DATA:\n",
    "            plot_filename = f\"figures/{dataset_name}_pseudo_pred_vs_actual_{temperature}.png\"\n",
    "        else:\n",
    "            plot_filename = f\"figures/{dataset_name}_pred_vs_actual_{temperature}.png\"\n",
    "        plt.savefig(plot_filename)\n",
    "        plt.close(fig)\n",
    "\n",
    "# Run experiments for each dataset\n",
    "\n",
    "# USE_PSEUDO_DATA = True\n",
    "# for dinfo in datasets_info:\n",
    "#     run_experiment(dinfo[\"name\"], dinfo[\"template\"])\n",
    "USE_PSEUDO_DATA = False\n",
    "for dinfo in datasets_info:\n",
    "    run_experiment(dinfo[\"name\"], dinfo[\"template\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
