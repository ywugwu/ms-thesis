{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 45\n",
      "['airplane',\n",
      " 'airport',\n",
      " 'baseball diamond',\n",
      " 'basketball court',\n",
      " 'beach',\n",
      " 'bridge',\n",
      " 'chaparral',\n",
      " 'church',\n",
      " 'circular farmland',\n",
      " 'cloud',\n",
      " 'commercial area',\n",
      " 'dense residential',\n",
      " 'desert',\n",
      " 'forest',\n",
      " 'freeway',\n",
      " 'golf course',\n",
      " 'ground track field',\n",
      " 'harbor',\n",
      " 'industrial area',\n",
      " 'intersection',\n",
      " 'island',\n",
      " 'lake',\n",
      " 'meadow',\n",
      " 'medium residential',\n",
      " 'mobile home park',\n",
      " 'mountain',\n",
      " 'overpass',\n",
      " 'palace',\n",
      " 'parking lot',\n",
      " 'railway',\n",
      " 'railway station',\n",
      " 'rectangular farmland',\n",
      " 'river',\n",
      " 'roundabout',\n",
      " 'runway',\n",
      " 'sea ice',\n",
      " 'ship',\n",
      " 'snowberg',\n",
      " 'sparse residential',\n",
      " 'stadium',\n",
      " 'storage tank',\n",
      " 'tennis court',\n",
      " 'terrace',\n",
      " 'thermal power station',\n",
      " 'wetland']\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45_global_traits.json\n",
      "Using OpenAI model: gpt-4o-mini-2024-07-18\n",
      "Configured to generate 32 captions.\n",
      "Meta Prompt: You are an AI assistant that generates creative and diverse image captions suitable for use with image generation models like DALL-E. Given a subject, provide 32 distinct, diverse and descriptive captions, considering the following global taxonomical traits when generating captions: ['Natural formations', 'Human-made structures', 'Recreational areas', 'Transportation infrastructure', 'Residential zones', 'Agricultural land use', 'Water bodies', 'Forested areas', 'Desert landscapes', 'Urban environments', 'Athletic facilities', 'Commercial zones', 'Industrial areas', 'Coastal features'].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Alternative Captions:  76%|███████▌  | 34/45 [00:00<00:00, 165.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\airplane.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\airport.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\baseball_diamond.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\basketball_court.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\beach.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\bridge.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\chaparral.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\church.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\circular_farmland.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\cloud.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\commercial_area.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\dense_residential.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\desert.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\forest.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\freeway.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\golf_course.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\ground_track_field.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\harbor.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\industrial_area.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\intersection.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\island.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\lake.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\meadow.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\medium_residential.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\mobile_home_park.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\mountain.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\overpass.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\palace.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\parking_lot.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\railway.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\railway_station.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\rectangular_farmland.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\river.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\roundabout.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Alternative Captions: 100%|██████████| 45/45 [00:00<00:00, 167.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\runway.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\sea_ice.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\ship.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\snowberg.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\sparse_residential.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\stadium.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\storage_tank.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\tennis_court.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\terrace.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\thermal_power_station.json\n",
      "Loaded data from cache: cache\\gpt-4o-mini-2024-07-18\\NWPU-RESISC45\\32\\wetland.json\n",
      "Processed batch 1/23\n",
      "Processed batch 2/23\n",
      "Processed batch 3/23\n",
      "Processed batch 4/23\n",
      "Processed batch 5/23\n",
      "Processed batch 6/23\n",
      "Processed batch 7/23\n",
      "Processed batch 8/23\n",
      "Processed batch 9/23\n",
      "Processed batch 10/23\n",
      "Processed batch 11/23\n",
      "Processed batch 12/23\n",
      "Processed batch 13/23\n",
      "Processed batch 14/23\n",
      "Processed batch 15/23\n",
      "Processed batch 16/23\n",
      "Processed batch 17/23\n",
      "Processed batch 18/23\n",
      "Processed batch 19/23\n",
      "Processed batch 20/23\n",
      "Processed batch 21/23\n",
      "Processed batch 22/23\n",
      "Processed batch 23/23\n",
      "Processed batch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 493/493 [04:40<00:00,  1.76it/s]\n",
      "Computing Zero-Shot Predictions: 100%|██████████| 31/31 [00:02<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Class Zero-Shot Accuracy Using Mean Text Embeddings:\n",
      "airplane: 6.86% (48/700)\n",
      "airport: 10.29% (72/700)\n",
      "baseball diamond: 91.86% (643/700)\n",
      "basketball court: 50.57% (354/700)\n",
      "beach: 62.57% (438/700)\n",
      "bridge: 17.00% (119/700)\n",
      "chaparral: 18.14% (127/700)\n",
      "church: 6.00% (42/700)\n",
      "circular farmland: 83.29% (583/700)\n",
      "cloud: 59.57% (417/700)\n",
      "commercial area: 0.00% (0/700)\n",
      "dense residential: 44.57% (312/700)\n",
      "desert: 95.29% (667/700)\n",
      "forest: 65.29% (457/700)\n",
      "freeway: 69.43% (486/700)\n",
      "golf course: 84.14% (589/700)\n",
      "ground track field: 17.14% (120/700)\n",
      "harbor: 81.00% (567/700)\n",
      "industrial area: 69.43% (486/700)\n",
      "intersection: 78.29% (548/700)\n",
      "island: 80.57% (564/700)\n",
      "lake: 66.57% (466/700)\n",
      "meadow: 0.00% (0/700)\n",
      "medium residential: 0.00% (0/700)\n",
      "mobile home park: 98.14% (687/700)\n",
      "mountain: 43.29% (303/700)\n",
      "overpass: 15.86% (111/700)\n",
      "palace: 18.00% (126/700)\n",
      "parking lot: 96.29% (674/700)\n",
      "railway: 13.00% (91/700)\n",
      "railway station: 23.14% (162/700)\n",
      "rectangular farmland: 91.14% (638/700)\n",
      "river: 41.00% (287/700)\n",
      "roundabout: 86.14% (603/700)\n",
      "runway: 76.57% (536/700)\n",
      "sea ice: 89.00% (623/700)\n",
      "ship: 58.86% (412/700)\n",
      "snowberg: 0.14% (1/700)\n",
      "sparse residential: 10.71% (75/700)\n",
      "stadium: 78.57% (550/700)\n",
      "storage tank: 56.71% (397/700)\n",
      "tennis court: 35.29% (247/700)\n",
      "terrace: 0.00% (0/700)\n",
      "thermal power station: 84.29% (590/700)\n",
      "wetland: 13.14% (92/700)\n",
      "\n",
      "Overall Zero-Shot Accuracy Using Mean Text Embeddings: 48.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Zero-Shot Predictions: 100%|██████████| 31/31 [00:02<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Class Zero-Shot Accuracy Using Standard Embeddings:\n",
      "airplane: 17.57% (123/700)\n",
      "airport: 73.29% (513/700)\n",
      "baseball diamond: 89.43% (626/700)\n",
      "basketball court: 47.57% (333/700)\n",
      "beach: 58.00% (406/700)\n",
      "bridge: 42.86% (300/700)\n",
      "chaparral: 0.00% (0/700)\n",
      "church: 12.29% (86/700)\n",
      "circular farmland: 86.43% (605/700)\n",
      "cloud: 59.86% (419/700)\n",
      "commercial area: 29.57% (207/700)\n",
      "dense residential: 80.29% (562/700)\n",
      "desert: 89.00% (623/700)\n",
      "forest: 74.29% (520/700)\n",
      "freeway: 75.14% (526/700)\n",
      "golf course: 97.86% (685/700)\n",
      "ground track field: 22.57% (158/700)\n",
      "harbor: 78.29% (548/700)\n",
      "industrial area: 63.57% (445/700)\n",
      "intersection: 78.00% (546/700)\n",
      "island: 93.14% (652/700)\n",
      "lake: 77.29% (541/700)\n",
      "meadow: 0.14% (1/700)\n",
      "medium residential: 1.43% (10/700)\n",
      "mobile home park: 97.86% (685/700)\n",
      "mountain: 41.57% (291/700)\n",
      "overpass: 18.14% (127/700)\n",
      "palace: 38.57% (270/700)\n",
      "parking lot: 91.71% (642/700)\n",
      "railway: 79.43% (556/700)\n",
      "railway station: 4.00% (28/700)\n",
      "rectangular farmland: 85.00% (595/700)\n",
      "river: 56.29% (394/700)\n",
      "roundabout: 93.71% (656/700)\n",
      "runway: 46.57% (326/700)\n",
      "sea ice: 98.29% (688/700)\n",
      "ship: 46.43% (325/700)\n",
      "snowberg: 30.00% (210/700)\n",
      "sparse residential: 35.29% (247/700)\n",
      "stadium: 83.00% (581/700)\n",
      "storage tank: 43.29% (303/700)\n",
      "tennis court: 45.00% (315/700)\n",
      "terrace: 0.00% (0/700)\n",
      "thermal power station: 71.71% (502/700)\n",
      "wetland: 13.14% (92/700)\n",
      "\n",
      "Overall Zero-Shot Accuracy Using Standard Embeddings: 54.82%\n",
      "\n",
      "Comparison of Per-Class Zero-Shot Accuracies:\n",
      "Class Name                     Mean Embedding Acc   Standard Embedding Acc\n",
      "airplane                       6.86% (48/700), 17.57% (123/700)\n",
      "airport                        10.29% (72/700), 73.29% (513/700)\n",
      "baseball diamond               91.86% (643/700), 89.43% (626/700)\n",
      "basketball court               50.57% (354/700), 47.57% (333/700)\n",
      "beach                          62.57% (438/700), 58.00% (406/700)\n",
      "bridge                         17.00% (119/700), 42.86% (300/700)\n",
      "chaparral                      18.14% (127/700), 0.00% (0/700)\n",
      "church                         6.00% (42/700), 12.29% (86/700)\n",
      "circular farmland              83.29% (583/700), 86.43% (605/700)\n",
      "cloud                          59.57% (417/700), 59.86% (419/700)\n",
      "commercial area                0.00% (0/700), 29.57% (207/700)\n",
      "dense residential              44.57% (312/700), 80.29% (562/700)\n",
      "desert                         95.29% (667/700), 89.00% (623/700)\n",
      "forest                         65.29% (457/700), 74.29% (520/700)\n",
      "freeway                        69.43% (486/700), 75.14% (526/700)\n",
      "golf course                    84.14% (589/700), 97.86% (685/700)\n",
      "ground track field             17.14% (120/700), 22.57% (158/700)\n",
      "harbor                         81.00% (567/700), 78.29% (548/700)\n",
      "industrial area                69.43% (486/700), 63.57% (445/700)\n",
      "intersection                   78.29% (548/700), 78.00% (546/700)\n",
      "island                         80.57% (564/700), 93.14% (652/700)\n",
      "lake                           66.57% (466/700), 77.29% (541/700)\n",
      "meadow                         0.00% (0/700), 0.14% (1/700)\n",
      "medium residential             0.00% (0/700), 1.43% (10/700)\n",
      "mobile home park               98.14% (687/700), 97.86% (685/700)\n",
      "mountain                       43.29% (303/700), 41.57% (291/700)\n",
      "overpass                       15.86% (111/700), 18.14% (127/700)\n",
      "palace                         18.00% (126/700), 38.57% (270/700)\n",
      "parking lot                    96.29% (674/700), 91.71% (642/700)\n",
      "railway                        13.00% (91/700), 79.43% (556/700)\n",
      "railway station                23.14% (162/700), 4.00% (28/700)\n",
      "rectangular farmland           91.14% (638/700), 85.00% (595/700)\n",
      "river                          41.00% (287/700), 56.29% (394/700)\n",
      "roundabout                     86.14% (603/700), 93.71% (656/700)\n",
      "runway                         76.57% (536/700), 46.57% (326/700)\n",
      "sea ice                        89.00% (623/700), 98.29% (688/700)\n",
      "ship                           58.86% (412/700), 46.43% (325/700)\n",
      "snowberg                       0.14% (1/700), 30.00% (210/700)\n",
      "sparse residential             10.71% (75/700), 35.29% (247/700)\n",
      "stadium                        78.57% (550/700), 83.00% (581/700)\n",
      "storage tank                   56.71% (397/700), 43.29% (303/700)\n",
      "tennis court                   35.29% (247/700), 45.00% (315/700)\n",
      "terrace                        0.00% (0/700), 0.00% (0/700)\n",
      "thermal power station          84.29% (590/700), 71.71% (502/700)\n",
      "wetland                        13.14% (92/700), 13.14% (92/700)\n",
      "\n",
      "Overall Zero-Shot Accuracy Using Mean Text Embeddings: 48.60%\n",
      "Overall Zero-Shot Accuracy Using Standard Embeddings: 54.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =========================\n",
    "# Import Necessary Libraries\n",
    "# =========================\n",
    "from utils.utils import CaptionGenerator\n",
    "from utils.dataset import get_dataset\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPModel, CLIPTokenizer, CLIPFeatureExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Configuration Parameters\n",
    "# =========================\n",
    "DATASET_NAME = 'NWPU-RESISC45'\n",
    "MODEL_NAME = \"openai/clip-vit-base-patch32\"\n",
    "BATCH_SIZE = 64         # Adjust based on your GPU memory\n",
    "KNN_BATCH_SIZE = 1024   # For zero-shot accuracy computation\n",
    "NUM_CAPTIONS = 32       # Number of alternative captions per class\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Load and Prepare Dataset\n",
    "# =========================\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Load dataset\n",
    "cub_dataset = get_dataset(DATASET_NAME)\n",
    "n_object = len(cub_dataset.classes)\n",
    "print(f\"Number of classes: {n_object}\")\n",
    "n_classes = cub_dataset.classes[:n_object]\n",
    "pprint.pprint(n_classes)\n",
    "# Update class_to_idx mapping for quick lookup\n",
    "cub_dataset.class_to_idx = {class_name: idx for idx, class_name in enumerate(cub_dataset.classes)}\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Generate Prompts and Captions\n",
    "# =========================\n",
    "\n",
    "# Generate standard prompts\n",
    "standard_prompts = [f\"a photo of a {class_name}\" for class_name in n_classes]\n",
    "standard_labels = n_classes  # Labels for standard prompts\n",
    "\n",
    "# Initialize CaptionGenerator and generate alternative captions\n",
    "capGenerator = CaptionGenerator(dataset_name=DATASET_NAME, class_names=n_classes, num_captions=NUM_CAPTIONS)\n",
    "\n",
    "alter_caption_list = []\n",
    "labels = []\n",
    "for class_name in tqdm(n_classes, desc=\"Generating Alternative Captions\"):\n",
    "    alter_captions = capGenerator.get_alternative_captions(class_name)\n",
    "    alter_caption_list.extend(alter_captions)\n",
    "    labels.extend([class_name] * len(alter_captions))\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Initialize CLIP Model and Tokenizers\n",
    "# =========================\n",
    "from utils.model_utils import get_text_embeddings, get_image_embeddings, load_model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_info = load_model(MODEL_NAME)\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Compute Text Embeddings\n",
    "# =========================\n",
    "# Get text embeddings for alternative captions\n",
    "text_embeddings = get_text_embeddings(alter_caption_list, model_info, device)\n",
    "text_labels = labels  # Labels for text embeddings\n",
    "\n",
    "# Create text_data entries\n",
    "text_data = [\n",
    "    {'embedding': emb, 'label': label, 'modality': 'text'}\n",
    "    for emb, label in zip(text_embeddings, text_labels)\n",
    "]\n",
    "\n",
    "# Get text embeddings for standard prompts\n",
    "standard_embeddings = get_text_embeddings(standard_prompts, model_info, device)\n",
    "standard_data = [\n",
    "    {'embedding': emb, 'label': label, 'modality': 'standard'}\n",
    "    for emb, label in zip(standard_embeddings, standard_labels)\n",
    "]\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Compute Image Embeddings for Real Images\n",
    "# =========================\n",
    "def get_image_loader(dataset, class_indices, batch_size, shuffle=False):\n",
    "    if hasattr(dataset, 'targets'):\n",
    "        selected_indices = [i for i, label in enumerate(dataset.targets) if label in class_indices]\n",
    "    else:\n",
    "        selected_indices = [i for i, (_, label) in enumerate(dataset.imgs) if label in class_indices]\n",
    "    selected_dataset = Subset(dataset, selected_indices)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        selected_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=lambda batch: (list(zip(*batch))[0], list(zip(*batch))[1])  # Exclude paths\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "selected_class_indices = [cub_dataset.class_to_idx[class_name] for class_name in n_classes]\n",
    "image_loader = get_image_loader(cub_dataset, selected_class_indices, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Get image embeddings and labels for real images\n",
    "image_embeddings, image_labels = get_image_embeddings(image_loader, model_info, device)\n",
    "\n",
    "# Map integer labels to class names\n",
    "image_labels = [cub_dataset.classes[label] for label in image_labels]\n",
    "\n",
    "# Create image_data entries\n",
    "image_data = [\n",
    "    {'embedding': emb, 'label': label, 'modality': 'image'}\n",
    "    for emb, label in zip(image_embeddings, image_labels)\n",
    "]\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Combine All Data\n",
    "# =========================\n",
    "combined_data = text_data + standard_data + image_data\n",
    "\n",
    "combined_embeddings = np.array([item['embedding'] for item in combined_data])\n",
    "combined_labels = [item['label'] for item in combined_data]\n",
    "combined_modalities = [item['modality'] for item in combined_data]\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Compute Zero-Shot Accuracy Function\n",
    "# =========================\n",
    "def compute_zero_shot_accuracy(image_embeddings, image_labels, text_embeddings, text_labels, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Compute zero-shot accuracy by matching image embeddings to text embeddings.\n",
    "\n",
    "    Args:\n",
    "        image_embeddings (np.ndarray): Image embeddings of shape [num_images, embedding_dim].\n",
    "        image_labels (List[str]): True labels for each image.\n",
    "        text_embeddings (np.ndarray): Text embeddings of shape [num_text_embeddings, embedding_dim].\n",
    "        text_labels (List[str]): Labels corresponding to each text embedding.\n",
    "        batch_size (int): Batch size for processing.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[dict, float, dict, dict, List[dict]]: Per-class accuracy, overall accuracy, class_correct counts,\n",
    "                                                     class_total counts, per-image predictions.\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    image_features = torch.from_numpy(image_embeddings).to(device)\n",
    "    text_features = torch.from_numpy(text_embeddings).to(device)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    image_features = F.normalize(image_features, p=2, dim=-1)\n",
    "    text_features = F.normalize(text_features, p=2, dim=-1)\n",
    "\n",
    "    num_images = image_features.size(0)\n",
    "    predicted_labels = []\n",
    "\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "\n",
    "    per_image_predictions = []\n",
    "\n",
    "    # Build mapping from class names to indices of text embeddings\n",
    "    class_to_text_indices = defaultdict(list)\n",
    "    for idx, class_name in enumerate(text_labels):\n",
    "        class_to_text_indices[class_name].append(idx)\n",
    "\n",
    "    # Prepare tensor of class names\n",
    "    class_names = list(class_to_text_indices.keys())\n",
    "\n",
    "    # For each class, get the indices of text embeddings\n",
    "    class_text_indices = [torch.tensor(class_to_text_indices[class_name], device=device) for class_name in class_names]\n",
    "\n",
    "    # We will compute per-class similarities by aggregating similarities\n",
    "\n",
    "    for start in tqdm(range(0, num_images, batch_size), desc=\"Computing Zero-Shot Predictions\"):\n",
    "        end = min(start + batch_size, num_images)\n",
    "        batch_image = image_features[start:end]  # Shape: [batch_size, embedding_dim]\n",
    "\n",
    "        # Compute similarities between batch images and text embeddings\n",
    "        similarities = batch_image @ text_features.T  # Shape: [batch_size, num_text_embeddings]\n",
    "\n",
    "        # For each class, aggregate similarities\n",
    "        batch_class_similarities = []\n",
    "        for indices in class_text_indices:\n",
    "            class_similarities = similarities[:, indices]  # Shape: [batch_size, num_texts_in_class]\n",
    "            # Aggregate similarities, e.g., by taking mean\n",
    "            class_similarity = class_similarities.mean(dim=1)  # Shape: [batch_size]\n",
    "            batch_class_similarities.append(class_similarity)\n",
    "        # Stack to get tensor of shape [batch_size, num_classes]\n",
    "        batch_class_similarities = torch.stack(batch_class_similarities, dim=1)  # Shape: [batch_size, num_classes]\n",
    "\n",
    "        # Now compute softmax over classes\n",
    "        probs = F.softmax(batch_class_similarities, dim=1)  # Shape: [batch_size, num_classes]\n",
    "\n",
    "        # Get top-5 predictions\n",
    "        topk = 5\n",
    "        topk_probs, topk_indices = probs.topk(topk, dim=1)  # Shape: [batch_size, topk]\n",
    "\n",
    "        # Map indices to class names\n",
    "        batch_topk_labels = [[class_names[idx] for idx in indices.cpu().numpy()] for indices in topk_indices]\n",
    "\n",
    "        # Get the predicted labels (top-1)\n",
    "        batch_predicted_labels = [labels[0] for labels in batch_topk_labels]\n",
    "        predicted_labels.extend(batch_predicted_labels)\n",
    "\n",
    "        # Update class_correct and class_total\n",
    "        for i, (true_label, pred_label) in enumerate(zip(image_labels[start:end], batch_predicted_labels)):\n",
    "            class_total[true_label] += 1\n",
    "            if true_label == pred_label:\n",
    "                class_correct[true_label] += 1\n",
    "\n",
    "            # Collect per-image predictions\n",
    "            per_image_prediction = {\n",
    "                'image_index': start + i,\n",
    "                'true_label': true_label,\n",
    "                'predicted_label': pred_label,\n",
    "                'top5_predicted_labels': batch_topk_labels[i],\n",
    "                'top5_predicted_probs': topk_probs[i].cpu().numpy().tolist()\n",
    "            }\n",
    "            per_image_predictions.append(per_image_prediction)\n",
    "\n",
    "    # Compute per-class accuracies\n",
    "    per_class_accuracy = {}\n",
    "    for class_name in set(image_labels):\n",
    "        if class_total[class_name] > 0:\n",
    "            accuracy = class_correct[class_name] / class_total[class_name]\n",
    "            per_class_accuracy[class_name] = accuracy\n",
    "        else:\n",
    "            per_class_accuracy[class_name] = None  # No samples for this class\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    total_correct = sum(class_correct.values())\n",
    "    total_samples = sum(class_total.values())\n",
    "    overall_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "\n",
    "    return per_class_accuracy, overall_accuracy, class_correct, class_total, per_image_predictions\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Compute Zero-Shot Accuracy Using Mean Text Embeddings\n",
    "# =========================\n",
    "# Organize text embeddings by class\n",
    "class_to_text_embeddings = defaultdict(list)\n",
    "for embedding, label in zip(text_embeddings, labels):\n",
    "    class_to_text_embeddings[label].append(embedding)\n",
    "\n",
    "# Compute per-class mean embeddings\n",
    "mean_text_embeddings = []\n",
    "mean_text_labels = []\n",
    "for class_name in n_classes:\n",
    "    embeddings = class_to_text_embeddings[class_name]\n",
    "    mean_embedding = np.mean(embeddings, axis=0)\n",
    "    mean_text_embeddings.append(mean_embedding)\n",
    "    mean_text_labels.append(class_name)\n",
    "\n",
    "mean_text_embeddings = np.array(mean_text_embeddings)  # Shape: CxD\n",
    "\n",
    "# Compute zero-shot accuracy using mean text embeddings\n",
    "mean_per_class_accuracy, mean_overall_accuracy, mean_class_correct, mean_class_total, _ = compute_zero_shot_accuracy(\n",
    "    image_embeddings=image_embeddings,\n",
    "    image_labels=image_labels,\n",
    "    text_embeddings=mean_text_embeddings,\n",
    "    text_labels=mean_text_labels,\n",
    "    batch_size=KNN_BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Display per-class accuracies\n",
    "print(\"\\nPer-Class Zero-Shot Accuracy Using Mean Text Embeddings:\")\n",
    "for class_name in n_classes:\n",
    "    accuracy = mean_per_class_accuracy[class_name]\n",
    "    if accuracy is not None:\n",
    "        print(f\"{class_name}: {accuracy:.2%} ({mean_class_correct[class_name]}/{mean_class_total[class_name]})\")\n",
    "    else:\n",
    "        print(f\"{class_name}: No samples\")\n",
    "\n",
    "print(f\"\\nOverall Zero-Shot Accuracy Using Mean Text Embeddings: {mean_overall_accuracy:.2%}\")\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Compute Zero-Shot Accuracy Using Standard Embeddings\n",
    "# =========================\n",
    "# Compute zero-shot accuracy using standard embeddings\n",
    "standard_per_class_accuracy, standard_overall_accuracy, standard_class_correct, standard_class_total, _ = compute_zero_shot_accuracy(\n",
    "    image_embeddings=image_embeddings,\n",
    "    image_labels=image_labels,\n",
    "    text_embeddings=standard_embeddings,\n",
    "    text_labels=standard_labels,\n",
    "    batch_size=KNN_BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Display per-class accuracies\n",
    "print(\"\\nPer-Class Zero-Shot Accuracy Using Standard Embeddings:\")\n",
    "for class_name in n_classes:\n",
    "    accuracy = standard_per_class_accuracy[class_name]\n",
    "    if accuracy is not None:\n",
    "        print(f\"{class_name}: {accuracy:.2%} ({standard_class_correct[class_name]}/{standard_class_total[class_name]})\")\n",
    "    else:\n",
    "        print(f\"{class_name}: No samples\")\n",
    "\n",
    "print(f\"\\nOverall Zero-Shot Accuracy Using Standard Embeddings: {standard_overall_accuracy:.2%}\")\n",
    "\n",
    "# %%\n",
    "# =========================\n",
    "# Compare the Results\n",
    "# =========================\n",
    "# Create a comparison table\n",
    "print(\"\\nComparison of Per-Class Zero-Shot Accuracies:\")\n",
    "print(f\"{'Class Name':30s} {'Mean Embedding Acc':20s} {'Standard Embedding Acc':20s}\")\n",
    "for class_name in n_classes:\n",
    "    mean_acc = mean_per_class_accuracy[class_name]\n",
    "    standard_acc = standard_per_class_accuracy[class_name]\n",
    "    if mean_acc is not None and standard_acc is not None:\n",
    "        print(f\"{class_name:30s} {mean_acc:.2%} ({mean_class_correct[class_name]}/{mean_class_total[class_name]}), \"\n",
    "              f\"{standard_acc:.2%} ({standard_class_correct[class_name]}/{standard_class_total[class_name]})\")\n",
    "    else:\n",
    "        print(f\"{class_name:30s} No samples\")\n",
    "\n",
    "# Compare overall accuracies\n",
    "print(f\"\\nOverall Zero-Shot Accuracy Using Mean Text Embeddings: {mean_overall_accuracy:.2%}\")\n",
    "print(f\"Overall Zero-Shot Accuracy Using Standard Embeddings: {standard_overall_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New story\n",
    "# P(cls|linearity score) = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
